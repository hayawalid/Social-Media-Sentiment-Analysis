{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "fcA3aUy5gXSz"
      ],
      "authorship_tag": "ABX9TyO+PFxuYvXF5j3E/ywNXXny",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/janaghoniem/Social-Media-Sentiment-Analysis/blob/main/ML_Arabic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "gQ80u7VsaXde"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from scipy.sparse import vstack\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "import warnings\n",
        "from sklearn.exceptions import ConvergenceWarning\n",
        "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import ast\n",
        "import re\n",
        "import pickle\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import tensorflow as tf\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')\n",
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Data Science/Arabic Sentiment/Datasets/arabic_sentiment_reviews.csv')\n",
        "with open(\"/content/drive/MyDrive/Colab Notebooks/Data Science/Arabic Sentiment/Features/training_data.pkl\", 'rb') as f:\n",
        "    training_data = pickle.load(f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pAIgQCb-fqfE",
        "outputId": "3edb7dbd-b29c-4bd3-a5b2-1546b7a29d01",
        "collapsed": true
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1) CatBoost ✅"
      ],
      "metadata": {
        "id": "fyLD107ug7KS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost"
      ],
      "metadata": {
        "id": "inHlLT_nWXYI",
        "collapsed": true,
        "outputId": "375f5af1-94e6-44ff-d07d-ed62faabfcf1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.8-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from catboost) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.11/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from catboost) (1.15.3)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (3.2.3)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly->catboost) (9.1.2)\n",
            "Downloading catboost-1.2.8-cp311-cp311-manylinux2014_x86_64.whl (99.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: catboost\n",
            "Successfully installed catboost-1.2.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from catboost import CatBoostClassifier\n",
        "\n",
        "# -------------------- Load Features and Labels --------------------\n",
        "X = training_data['X_fasttext']  # FastText dense vectors\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(df['label'])\n",
        "\n",
        "# -------------------- Train/Validation/Test Split --------------------\n",
        "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.1, stratify=y_temp, random_state=42)\n",
        "\n",
        "# -------------------- Baseline CatBoost Training --------------------\n",
        "print(\"\\nTraining Baseline CatBoost...\")\n",
        "\n",
        "baseline_cb = CatBoostClassifier(\n",
        "    iterations=100,\n",
        "    loss_function='MultiClass',\n",
        "    random_seed=42,\n",
        "    verbose=0  # Suppress CatBoost output\n",
        ")\n",
        "\n",
        "baseline_cb.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "train_preds = baseline_cb.predict(X_train)\n",
        "val_preds = baseline_cb.predict(X_val)\n",
        "test_preds = baseline_cb.predict(X_test)\n",
        "\n",
        "print(\"\\nBaseline CatBoost Results:\")\n",
        "print(\"Training Accuracy:\", accuracy_score(y_train, train_preds))\n",
        "print(\"Validation Accuracy:\", accuracy_score(y_val, val_preds))\n",
        "print(\"Testing Accuracy:\", accuracy_score(y_test, test_preds))\n",
        "\n",
        "# -------------------- CatBoost Hyperparameter Tuning --------------------\n",
        "print(\"\\nStarting CatBoost hyperparameter tuning...\")\n",
        "\n",
        "cb_params = {\n",
        "    'depth': [4, 6],\n",
        "    'learning_rate': [0.1, 0.01],\n",
        "    'iterations': [100, 200],\n",
        "    'l2_leaf_reg': [1, 3]\n",
        "}\n",
        "\n",
        "cb_model = CatBoostClassifier(\n",
        "    loss_function='MultiClass',\n",
        "    random_seed=42,\n",
        "    verbose=0\n",
        ")\n",
        "\n",
        "cb_grid = GridSearchCV(estimator=cb_model,\n",
        "                       param_grid=cb_params,\n",
        "                       cv=3,\n",
        "                       n_jobs=-1,\n",
        "                       verbose=1)\n",
        "\n",
        "cb_grid.fit(X_train, y_train)\n",
        "best_cb = cb_grid.best_estimator_\n",
        "\n",
        "# Predictions after tuning\n",
        "cb_train_preds = best_cb.predict(X_train)\n",
        "cb_val_preds = best_cb.predict(X_val)\n",
        "cb_test_preds = best_cb.predict(X_test)\n",
        "\n",
        "print(\"\\nTuned CatBoost Results:\")\n",
        "print(\"Best Parameters:\", cb_grid.best_params_)\n",
        "print(\"Training Accuracy:\", accuracy_score(y_train, cb_train_preds))\n",
        "print(\"Validation Accuracy:\", accuracy_score(y_val, cb_val_preds))\n",
        "print(\"Testing Accuracy:\", accuracy_score(y_test, cb_test_preds))\n"
      ],
      "metadata": {
        "id": "R4LDdqpLfrh9",
        "outputId": "ce21f90a-1d0c-4a81-b494-8ae49bfb3fb8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training Baseline CatBoost...\n",
            "\n",
            "Baseline CatBoost Results:\n",
            "Training Accuracy: 0.796952861952862\n",
            "Validation Accuracy: 0.7840909090909091\n",
            "Testing Accuracy: 0.7806666666666666\n",
            "\n",
            "Starting CatBoost hyperparameter tuning...\n",
            "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
            "\n",
            "Tuned CatBoost Results:\n",
            "Best Parameters: {'depth': 6, 'iterations': 200, 'l2_leaf_reg': 3, 'learning_rate': 0.1}\n",
            "Training Accuracy: 0.7831523569023568\n",
            "Validation Accuracy: 0.7764772727272727\n",
            "Testing Accuracy: 0.7750757575757575\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, roc_auc_score\n",
        "import tensorflow as tf  # For tf.keras.utils.to_categorical\n",
        "\n",
        "# -------------------- Baseline CatBoost Classification Report and AUC-ROC --------------------\n",
        "print(\"\\nClassification Report (Baseline CatBoost - Test Data):\")\n",
        "baseline_cb_preds = baseline_cb.predict(X_test)\n",
        "print(classification_report(y_test, baseline_cb_preds, target_names=[str(cls) for cls in label_encoder.classes_]))\n",
        "\n",
        "try:\n",
        "    baseline_cb_probs = baseline_cb.predict_proba(X_test)  # shape: (n_samples, n_classes)\n",
        "    y_test_one_hot = tf.keras.utils.to_categorical(y_test, num_classes=len(label_encoder.classes_))\n",
        "    auc_baseline_cb = roc_auc_score(y_test_one_hot, baseline_cb_probs, multi_class='ovr', average='macro')\n",
        "    print(\"AUC-ROC (macro average OvR) Baseline CatBoost:\", auc_baseline_cb)\n",
        "except Exception as e:\n",
        "    print(\"AUC-ROC (Baseline CatBoost) could not be calculated:\", e)\n",
        "\n",
        "\n",
        "# -------------------- Tuned CatBoost Classification Report and AUC-ROC --------------------\n",
        "print(\"\\nClassification Report (Tuned CatBoost - Test Data):\")\n",
        "cb_tuned_preds = best_cb.predict(X_test)\n",
        "print(classification_report(y_test, cb_tuned_preds, target_names=[str(cls) for cls in label_encoder.classes_]))\n",
        "\n",
        "try:\n",
        "    cb_tuned_probs = best_cb.predict_proba(X_test)\n",
        "    y_test_one_hot = tf.keras.utils.to_categorical(y_test, num_classes=len(label_encoder.classes_))\n",
        "    auc_tuned_cb = roc_auc_score(y_test_one_hot, cb_tuned_probs, multi_class='ovr', average='macro')\n",
        "    print(\"AUC-ROC (macro average OvR) Tuned CatBoost:\", auc_tuned_cb)\n",
        "except Exception as e:\n",
        "    print(\"AUC-ROC (Tuned CatBoost) could not be calculated:\", e)\n"
      ],
      "metadata": {
        "id": "ieU6YN1qWJlZ",
        "outputId": "fc725442-4927-46f0-c72c-c8ad0a44d9e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report (Baseline CatBoost - Test Data):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.79      0.78     32629\n",
            "           1       0.79      0.77      0.78     33371\n",
            "\n",
            "    accuracy                           0.78     66000\n",
            "   macro avg       0.78      0.78      0.78     66000\n",
            "weighted avg       0.78      0.78      0.78     66000\n",
            "\n",
            "AUC-ROC (macro average OvR) Baseline CatBoost: 0.8631905655763421\n",
            "\n",
            "Classification Report (Tuned CatBoost - Test Data):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.79      0.78     32629\n",
            "           1       0.79      0.76      0.77     33371\n",
            "\n",
            "    accuracy                           0.78     66000\n",
            "   macro avg       0.78      0.78      0.78     66000\n",
            "weighted avg       0.78      0.78      0.78     66000\n",
            "\n",
            "AUC-ROC (macro average OvR) Tuned CatBoost: 0.8571223293613733\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2) SVM ✅"
      ],
      "metadata": {
        "id": "AOXvTmD6hSN-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import tensorflow as tf\n",
        "\n",
        "# Load features and labels\n",
        "X = training_data['X_fasttext']  # Use your dense FastText embeddings\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(df['label'])\n",
        "y_cat = tf.keras.utils.to_categorical(y)\n",
        "\n",
        "# Split into train, validation, test (stratifying on labels)\n",
        "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.1, stratify=y_temp, random_state=42)\n",
        "\n",
        "# ----------------- Baseline SVM -----------------\n",
        "print(\"\\nTraining Baseline SVM...\")\n",
        "svm_baseline = LinearSVC(max_iter=10000, random_state=42, dual=False)\n",
        "svm_baseline.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "train_preds = svm_baseline.predict(X_train)\n",
        "val_preds = svm_baseline.predict(X_val)\n",
        "test_preds = svm_baseline.predict(X_test)\n",
        "\n",
        "print(\"\\nBaseline SVM Results:\")\n",
        "print(\"Training Accuracy:\", accuracy_score(y_train, train_preds))\n",
        "print(\"Validation Accuracy:\", accuracy_score(y_val, val_preds))\n",
        "print(\"Testing Accuracy:\", accuracy_score(y_test, test_preds))\n",
        "\n",
        "# ----------------- SVM Hyperparameter Tuning -----------------\n",
        "print(\"\\nStarting SVM hyperparameter tuning...\")\n",
        "svm_params = {\n",
        "    'C': [0.1, 1, 10, 100],\n",
        "    'penalty': ['l2'],\n",
        "    'loss': ['squared_hinge'],\n",
        "    'dual': [False]\n",
        "}\n",
        "\n",
        "svm_grid = GridSearchCV(\n",
        "    LinearSVC(random_state=42, max_iter=10000),\n",
        "    svm_params,\n",
        "    cv=3,\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Fit ONLY on X_train (avoid stacking with val)\n",
        "svm_grid.fit(X_train, y_train)\n",
        "best_svm = svm_grid.best_estimator_\n",
        "\n",
        "# Predictions after tuning\n",
        "svm_train_preds = best_svm.predict(X_train)\n",
        "svm_val_preds = best_svm.predict(X_val)\n",
        "svm_test_preds = best_svm.predict(X_test)\n",
        "\n",
        "print(\"\\nTuned SVM Results:\")\n",
        "print(\"Best Parameters:\", svm_grid.best_params_)\n",
        "print(\"Training Accuracy:\", accuracy_score(y_train, svm_train_preds))\n",
        "print(\"Validation Accuracy:\", accuracy_score(y_val, svm_val_preds))\n",
        "print(\"Testing Accuracy:\", accuracy_score(y_test, svm_test_preds))\n"
      ],
      "metadata": {
        "id": "OtyTu2sihTOk",
        "outputId": "8bcb7009-13eb-4288-d0d6-73d95a16175a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training Baseline SVM...\n",
            "\n",
            "Baseline SVM Results:\n",
            "Training Accuracy: 0.798956228956229\n",
            "Validation Accuracy: 0.7990909090909091\n",
            "Testing Accuracy: 0.7961818181818182\n",
            "\n",
            "Starting SVM hyperparameter tuning...\n",
            "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
            "\n",
            "Tuned SVM Results:\n",
            "Best Parameters: {'C': 10, 'dual': False, 'loss': 'squared_hinge', 'penalty': 'l2'}\n",
            "Training Accuracy: 0.7989814814814815\n",
            "Validation Accuracy: 0.7992803030303031\n",
            "Testing Accuracy: 0.7964545454545454\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, roc_auc_score\n",
        "\n",
        "# ---- Classification Report ----\n",
        "print(\"\\nClassification Report (Test Data):\")\n",
        "print(classification_report(y_test, test_preds, target_names=[str(cls) for cls in label_encoder.classes_]))\n",
        "\n",
        "# ---- AUC-ROC (using decision_function) ----\n",
        "try:\n",
        "    test_decision_scores = svm_baseline.decision_function(X_test)\n",
        "    auc = roc_auc_score(y_test, test_decision_scores, multi_class='ovr', average='macro')\n",
        "    print(\"AUC-ROC (macro average OvR):\", auc)\n",
        "except Exception as e:\n",
        "    print(\"AUC-ROC could not be calculated:\", e)\n",
        "\n",
        "from sklearn.metrics import classification_report, roc_auc_score\n",
        "\n",
        "# ---- Classification Report (Tuned SVM) ----\n",
        "print(\"\\nClassification Report (Tuned SVM - Test Data):\")\n",
        "print(classification_report(y_test, svm_test_preds, target_names=[str(cls) for cls in label_encoder.classes_]))\n",
        "\n",
        "# ---- AUC-ROC (using decision_function for Tuned SVM) ----\n",
        "try:\n",
        "    test_decision_scores_tuned = best_svm.decision_function(X_test)\n",
        "    auc_tuned = roc_auc_score(y_test, test_decision_scores_tuned, multi_class='ovr', average='macro')\n",
        "    print(\"AUC-ROC (macro average OvR) Tuned SVM:\", auc_tuned)\n",
        "except Exception as e:\n",
        "    print(\"AUC-ROC (Tuned SVM) could not be calculated:\", e)\n",
        "\n"
      ],
      "metadata": {
        "id": "ycNjJm9K8i3A",
        "outputId": "0feb7f3a-a11c-4b0b-b285-b197c247ea1f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report (Test Data):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.77      0.68     32629\n",
            "           1       0.70      0.52      0.60     33371\n",
            "\n",
            "    accuracy                           0.64     66000\n",
            "   macro avg       0.65      0.64      0.64     66000\n",
            "weighted avg       0.65      0.64      0.64     66000\n",
            "\n",
            "AUC-ROC (macro average OvR): 0.8760152659478608\n",
            "\n",
            "Classification Report (Tuned SVM - Test Data):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.81      0.80     32629\n",
            "           1       0.81      0.79      0.80     33371\n",
            "\n",
            "    accuracy                           0.80     66000\n",
            "   macro avg       0.80      0.80      0.80     66000\n",
            "weighted avg       0.80      0.80      0.80     66000\n",
            "\n",
            "AUC-ROC (macro average OvR) Tuned SVM: 0.8760306967319824\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3) Logistic regression ✅"
      ],
      "metadata": {
        "id": "s32o3qjihjgq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import tensorflow as tf\n",
        "\n",
        "# Load features and labels\n",
        "X = training_data['X_fasttext']  # Use your dense FastText embeddings\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(df['label'])\n",
        "y_cat = tf.keras.utils.to_categorical(y)\n",
        "\n",
        "# Split into train, validation, test (stratifying on labels)\n",
        "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.1, stratify=y_temp, random_state=42)\n",
        "\n",
        "# ----------------- Baseline Logistic Regression -----------------\n",
        "print(\"\\nTraining Baseline Logistic Regression...\")\n",
        "logreg_baseline = LogisticRegression(max_iter=10000, random_state=42, solver='lbfgs', multi_class='multinomial')\n",
        "logreg_baseline.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "train_preds = logreg_baseline.predict(X_train)\n",
        "val_preds = logreg_baseline.predict(X_val)\n",
        "test_preds = logreg_baseline.predict(X_test)\n",
        "\n",
        "print(\"\\nBaseline Logistic Regression Results:\")\n",
        "print(\"Training Accuracy:\", accuracy_score(y_train, train_preds))\n",
        "print(\"Validation Accuracy:\", accuracy_score(y_val, val_preds))\n",
        "print(\"Testing Accuracy:\", accuracy_score(y_test, test_preds))\n",
        "\n",
        "# ----------------- Logistic Regression Hyperparameter Tuning -----------------\n",
        "print(\"\\nStarting Logistic Regression hyperparameter tuning...\")\n",
        "logreg_params = {\n",
        "    'C': [0.01, 0.1, 1, 10, 100],\n",
        "    'penalty': ['l2'],\n",
        "    'solver': ['lbfgs'],  # Good for multiclass\n",
        "    'multi_class': ['multinomial']\n",
        "}\n",
        "\n",
        "logreg_grid = GridSearchCV(\n",
        "    LogisticRegression(max_iter=10000, random_state=42),\n",
        "    logreg_params,\n",
        "    cv=3,\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Fit ONLY on X_train\n",
        "logreg_grid.fit(X_train, y_train)\n",
        "best_logreg = logreg_grid.best_estimator_\n",
        "\n",
        "# Predictions after tuning\n",
        "logreg_train_preds = best_logreg.predict(X_train)\n",
        "logreg_val_preds = best_logreg.predict(X_val)\n",
        "logreg_test_preds = best_logreg.predict(X_test)\n",
        "\n",
        "print(\"\\nTuned Logistic Regression Results:\")\n",
        "print(\"Best Parameters:\", logreg_grid.best_params_)\n",
        "print(\"Training Accuracy:\", accuracy_score(y_train, logreg_train_preds))\n",
        "print(\"Validation Accuracy:\", accuracy_score(y_val, logreg_val_preds))\n",
        "print(\"Testing Accuracy:\", accuracy_score(y_test, logreg_test_preds))\n"
      ],
      "metadata": {
        "id": "uzOt86EJhiu2",
        "outputId": "add09d79-8ff7-4807-a3b5-a3af98512715",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training Baseline Logistic Regression...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1237: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Baseline Logistic Regression Results:\n",
            "Training Accuracy: 0.796986531986532\n",
            "Validation Accuracy: 0.7985227272727272\n",
            "Testing Accuracy: 0.7941666666666667\n",
            "\n",
            "Starting Logistic Regression hyperparameter tuning...\n",
            "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1237: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Tuned Logistic Regression Results:\n",
            "Best Parameters: {'C': 100, 'multi_class': 'multinomial', 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "Training Accuracy: 0.7981060606060606\n",
            "Validation Accuracy: 0.798939393939394\n",
            "Testing Accuracy: 0.7962575757575757\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, roc_auc_score\n",
        "\n",
        "# ---- Classification Report (Baseline Logistic Regression) ----\n",
        "print(\"\\nClassification Report (Baseline Logistic Regression - Test Data):\")\n",
        "print(classification_report(y_test, test_preds, target_names=[str(cls) for cls in label_encoder.classes_]))\n",
        "\n",
        "# ---- AUC-ROC (using decision_function for Baseline Logistic Regression) ----\n",
        "try:\n",
        "    test_decision_scores_baseline = logreg_baseline.decision_function(X_test)\n",
        "    auc_baseline = roc_auc_score(y_test, test_decision_scores_baseline, multi_class='ovr', average='macro')\n",
        "    print(\"AUC-ROC (macro average OvR) Baseline Logistic Regression:\", auc_baseline)\n",
        "except Exception as e:\n",
        "    print(\"AUC-ROC (Baseline Logistic Regression) could not be calculated:\", e)\n",
        "\n",
        "\n",
        "# ---- Classification Report (Tuned Logistic Regression) ----\n",
        "print(\"\\nClassification Report (Tuned Logistic Regression - Test Data):\")\n",
        "print(classification_report(y_test, logreg_test_preds, target_names=[str(cls) for cls in label_encoder.classes_]))\n",
        "\n",
        "# ---- AUC-ROC (using decision_function for Tuned Logistic Regression) ----\n",
        "try:\n",
        "    test_decision_scores_tuned = best_logreg.decision_function(X_test)\n",
        "    auc_tuned = roc_auc_score(y_test, test_decision_scores_tuned, multi_class='ovr', average='macro')\n",
        "    print(\"AUC-ROC (macro average OvR) Tuned Logistic Regression:\", auc_tuned)\n",
        "except Exception as e:\n",
        "    print(\"AUC-ROC (Tuned Logistic Regression) could not be calculated:\", e)\n"
      ],
      "metadata": {
        "id": "cmAH8uKm9Lrk",
        "outputId": "5cb4896e-2211-4295-c53d-cbfa37a0e511",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report (Baseline Logistic Regression - Test Data):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.77      0.68     32629\n",
            "           1       0.70      0.52      0.60     33371\n",
            "\n",
            "    accuracy                           0.64     66000\n",
            "   macro avg       0.65      0.64      0.64     66000\n",
            "weighted avg       0.65      0.64      0.64     66000\n",
            "\n",
            "AUC-ROC (macro average OvR) Baseline Logistic Regression: 0.8741980417747179\n",
            "\n",
            "Classification Report (Tuned Logistic Regression - Test Data):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.80      0.80     32629\n",
            "           1       0.81      0.79      0.80     33371\n",
            "\n",
            "    accuracy                           0.80     66000\n",
            "   macro avg       0.80      0.80      0.80     66000\n",
            "weighted avg       0.80      0.80      0.80     66000\n",
            "\n",
            "AUC-ROC (macro average OvR) Tuned Logistic Regression: 0.875517256263241\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4) Naive Bayes ✅"
      ],
      "metadata": {
        "id": "30rzbGl7hv4t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import tensorflow as tf\n",
        "\n",
        "# Load features and labels\n",
        "X = training_data['X_fasttext']\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(df['label'])\n",
        "\n",
        "# Split into train, validation, test (stratifying on labels)\n",
        "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.1, stratify=y_temp, random_state=42)\n",
        "\n",
        "# ----------------- Baseline Gaussian Naive Bayes -----------------\n",
        "print(\"\\nTraining Baseline Gaussian Naive Bayes...\")\n",
        "nb_baseline = GaussianNB()\n",
        "nb_baseline.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "train_preds = nb_baseline.predict(X_train)\n",
        "val_preds = nb_baseline.predict(X_val)\n",
        "test_preds = nb_baseline.predict(X_test)\n",
        "\n",
        "print(\"\\nBaseline Gaussian Naive Bayes Results:\")\n",
        "print(\"Training Accuracy:\", accuracy_score(y_train, train_preds))\n",
        "print(\"Validation Accuracy:\", accuracy_score(y_val, val_preds))\n",
        "print(\"Testing Accuracy:\", accuracy_score(y_test, test_preds))\n",
        "\n",
        "# ----------------- Naive Bayes Hyperparameter Tuning -----------------\n",
        "# For GaussianNB, the main hyperparameter is var_smoothing (default: 1e-9)\n",
        "print(\"\\nStarting Gaussian Naive Bayes hyperparameter tuning...\")\n",
        "nb_params = {\n",
        "    'var_smoothing': [1e-9, 1e-8, 1e-7, 1e-6, 1e-5]\n",
        "}\n",
        "\n",
        "nb_grid = GridSearchCV(\n",
        "    GaussianNB(),\n",
        "    nb_params,\n",
        "    cv=3,\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Fit ONLY on X_train\n",
        "nb_grid.fit(X_train, y_train)\n",
        "best_nb = nb_grid.best_estimator_\n",
        "\n",
        "# Predictions after tuning\n",
        "nb_train_preds = best_nb.predict(X_train)\n",
        "nb_val_preds = best_nb.predict(X_val)\n",
        "nb_test_preds = best_nb.predict(X_test)\n",
        "\n",
        "print(\"\\nTuned Gaussian Naive Bayes Results:\")\n",
        "print(\"Best Parameters:\", nb_grid.best_params_)\n",
        "print(\"Training Accuracy:\", accuracy_score(y_train, nb_train_preds))\n",
        "print(\"Validation Accuracy:\", accuracy_score(y_val, nb_val_preds))\n",
        "print(\"Testing Accuracy:\", accuracy_score(y_test, nb_test_preds))\n"
      ],
      "metadata": {
        "id": "5UKsCXImhxHf",
        "outputId": "c77aff8e-ddb8-47b6-cc48-90e722a872a5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training Baseline Gaussian Naive Bayes...\n",
            "\n",
            "Baseline Gaussian Naive Bayes Results:\n",
            "Training Accuracy: 0.6434175084175084\n",
            "Validation Accuracy: 0.6449621212121213\n",
            "Testing Accuracy: 0.6429090909090909\n",
            "\n",
            "Starting Gaussian Naive Bayes hyperparameter tuning...\n",
            "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
            "\n",
            "Tuned Gaussian Naive Bayes Results:\n",
            "Best Parameters: {'var_smoothing': 1e-05}\n",
            "Training Accuracy: 0.6433964646464646\n",
            "Validation Accuracy: 0.645\n",
            "Testing Accuracy: 0.6428939393939394\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, roc_auc_score\n",
        "\n",
        "# ---- Classification Report (Baseline Naive Bayes) ----\n",
        "print(\"\\nClassification Report (Baseline Gaussian Naive Bayes - Test Data):\")\n",
        "print(classification_report(y_test, test_preds, target_names=[str(cls) for cls in label_encoder.classes_]))\n",
        "\n",
        "# ---- AUC-ROC (Baseline Naive Bayes) ----\n",
        "try:\n",
        "    test_prob_scores_baseline = nb_baseline.predict_proba(X_test)\n",
        "    auc_baseline = roc_auc_score(y_test, test_prob_scores_baseline, multi_class='ovr', average='macro')\n",
        "    print(\"AUC-ROC (macro average OvR) Baseline Naive Bayes:\", auc_baseline)\n",
        "except Exception as e:\n",
        "    print(\"AUC-ROC (Baseline Naive Bayes) could not be calculated:\", e)\n",
        "\n",
        "# ---- Classification Report (Tuned Naive Bayes) ----\n",
        "print(\"\\nClassification Report (Tuned Gaussian Naive Bayes - Test Data):\")\n",
        "print(classification_report(y_test, nb_test_preds, target_names=[str(cls) for cls in label_encoder.classes_]))\n",
        "\n",
        "# ---- AUC-ROC (Tuned Naive Bayes) ----\n",
        "try:\n",
        "    test_prob_scores_tuned = best_nb.predict_proba(X_test)\n",
        "    auc_tuned = roc_auc_score(y_test, test_prob_scores_tuned, multi_class='ovr', average='macro')\n",
        "    print(\"AUC-ROC (macro average OvR) Tuned Naive Bayes:\", auc_tuned)\n",
        "except Exception as e:\n",
        "    print(\"AUC-ROC (Tuned Naive Bayes) could not be calculated:\", e)\n",
        "\n"
      ],
      "metadata": {
        "id": "7SuzoEzF9ad4",
        "outputId": "85d1b31c-eae9-4f15-f347-9ce7a6ddb8b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report (Baseline Gaussian Naive Bayes - Test Data):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.77      0.68     32629\n",
            "           1       0.70      0.52      0.60     33371\n",
            "\n",
            "    accuracy                           0.64     66000\n",
            "   macro avg       0.65      0.64      0.64     66000\n",
            "weighted avg       0.65      0.64      0.64     66000\n",
            "\n",
            "AUC-ROC (Baseline Naive Bayes) could not be calculated: y should be a 1d array, got an array of shape (66000, 2) instead.\n",
            "\n",
            "Classification Report (Tuned Gaussian Naive Bayes - Test Data):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.77      0.68     32629\n",
            "           1       0.70      0.52      0.60     33371\n",
            "\n",
            "    accuracy                           0.64     66000\n",
            "   macro avg       0.65      0.64      0.64     66000\n",
            "weighted avg       0.65      0.64      0.64     66000\n",
            "\n",
            "AUC-ROC (Tuned Naive Bayes) could not be calculated: y should be a 1d array, got an array of shape (66000, 2) instead.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5) MLP"
      ],
      "metadata": {
        "id": "D3uPQyvz0e35"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikeras"
      ],
      "metadata": {
        "collapsed": true,
        "id": "88uaOsRz2TXb",
        "outputId": "ef3fd088-fca0-42c7-fe56-c48896a7da99",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikeras in /usr/local/lib/python3.11/dist-packages (0.13.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from scikeras) (3.8.0)\n",
            "Requirement already satisfied: scikit-learn>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from scikeras) (1.6.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (2.0.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (0.0.9)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (3.13.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (0.15.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (0.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (24.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.4.2->scikeras) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.4.2->scikeras) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.4.2->scikeras) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from optree->keras>=3.2.0->scikeras) (4.13.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.2.0->scikeras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.2.0->scikeras) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->scikeras) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load features and labels\n",
        "X = training_data['X_fasttext']  # Use your dense FastText embeddings\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(df['label'])\n",
        "\n",
        "# Split into train, validation, test (stratifying on labels)\n",
        "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.1, stratify=y_temp, random_state=42)\n",
        "\n",
        "# ----------------- Baseline MLP -----------------\n",
        "print(\"\\nTraining Baseline MLP...\")\n",
        "baseline_mlp = MLPClassifier(hidden_layer_sizes=(128,), activation='relu', solver='adam', max_iter=300, random_state=42)\n",
        "baseline_mlp.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "train_preds = baseline_mlp.predict(X_train)\n",
        "val_preds = baseline_mlp.predict(X_val)\n",
        "test_preds = baseline_mlp.predict(X_test)\n",
        "\n",
        "print(\"\\nBaseline MLP Results:\")\n",
        "print(\"Training Accuracy:\", accuracy_score(y_train, train_preds))\n",
        "print(\"Validation Accuracy:\", accuracy_score(y_val, val_preds))\n",
        "print(\"Testing Accuracy:\", accuracy_score(y_test, test_preds))\n",
        "\n",
        "# ----------------- MLP Hyperparameter Tuning -----------------\n",
        "print(\"\\nStarting MLP hyperparameter tuning...\")\n",
        "\n",
        "param_grid = {\n",
        "    'hidden_layer_sizes': [(64,), (128,), (256,)],\n",
        "    'activation': ['relu', 'tanh'],\n",
        "    'solver': ['adam', 'sgd'],\n",
        "    'batch_size': [32, 64],\n",
        "    'max_iter': [300]\n",
        "}\n",
        "\n",
        "mlp_grid = GridSearchCV(MLPClassifier(random_state=42), param_grid, cv=3, n_jobs=-1, verbose=1)\n",
        "mlp_grid.fit(X_train, y_train)\n",
        "\n",
        "best_mlp = mlp_grid.best_estimator_\n",
        "\n",
        "# Predictions after tuning\n",
        "mlp_train_preds = best_mlp.predict(X_train)\n",
        "mlp_val_preds = best_mlp.predict(X_val)\n",
        "mlp_test_preds = best_mlp.predict(X_test)\n",
        "\n",
        "print(\"\\nTuned MLP Results:\")\n",
        "print(\"Best Parameters:\", mlp_grid.best_params_)\n",
        "print(\"Training Accuracy:\", accuracy_score(y_train, mlp_train_preds))\n",
        "print(\"Validation Accuracy:\", accuracy_score(y_val, mlp_val_preds))\n",
        "print(\"Testing Accuracy:\", accuracy_score(y_test, mlp_test_preds))\n"
      ],
      "metadata": {
        "id": "hEfQLnzmKuv7",
        "outputId": "129a895e-071d-40c7-ac4d-469d5892b50d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training Baseline MLP...\n",
            "\n",
            "Baseline MLP Results:\n",
            "Training Accuracy: 0.8820538720538721\n",
            "Validation Accuracy: 0.8123863636363636\n",
            "Testing Accuracy: 0.8077272727272727\n",
            "\n",
            "Starting MLP hyperparameter tuning...\n",
            "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, roc_auc_score\n",
        "\n",
        "# -------------------- Baseline MLP Classification Report and AUC-ROC --------------------\n",
        "print(\"\\nClassification Report (Baseline MLP - Test Data):\")\n",
        "print(classification_report(y_test, test_preds, target_names=[str(cls) for cls in label_encoder.classes_]))\n",
        "\n",
        "# AUC-ROC for Baseline MLP\n",
        "try:\n",
        "    test_probs_baseline = baseline_mlp.predict(X_test)  # shape: (n_samples, n_classes)\n",
        "    auc_baseline = roc_auc_score(tf.keras.utils.to_categorical(y_test), test_probs_baseline, multi_class='ovr', average='macro')\n",
        "    print(\"AUC-ROC (macro average OvR) Baseline MLP:\", auc_baseline)\n",
        "except Exception as e:\n",
        "    print(\"AUC-ROC (Baseline MLP) could not be calculated:\", e)\n",
        "\n",
        "# -------------------- Tuned MLP Classification Report and AUC-ROC --------------------\n",
        "print(\"\\nClassification Report (Tuned MLP - Test Data):\")\n",
        "print(classification_report(y_test, mlp_test_preds, target_names=[str(cls) for cls in label_encoder.classes_]))\n",
        "\n",
        "# AUC-ROC for Tuned MLP\n",
        "try:\n",
        "    test_probs_tuned = best_mlp.model.predict(X_test)  # shape: (n_samples, n_classes)\n",
        "    auc_tuned = roc_auc_score(tf.keras.utils.to_categorical(y_test), test_probs_tuned, multi_class='ovr', average='macro')\n",
        "    print(\"AUC-ROC (macro average OvR) Tuned MLP:\", auc_tuned)\n",
        "except Exception as e:\n",
        "    print(\"AUC-ROC (Tuned MLP) could not be calculated:\", e)\n"
      ],
      "metadata": {
        "id": "_SK17pq91OGT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6) XGBoost ✅"
      ],
      "metadata": {
        "id": "O8u-bBne0f5a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import xgboost as xgb\n",
        "\n",
        "# -------------------- Load Features and Labels --------------------\n",
        "X = training_data['X_fasttext']  # FastText dense vectors\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(df['label'])\n",
        "\n",
        "# -------------------- Train/Validation/Test Split --------------------\n",
        "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.1, stratify=y_temp, random_state=42)\n",
        "\n",
        "# -------------------- Baseline XGBoost Training --------------------\n",
        "print(\"\\nTraining Baseline XGBoost...\")\n",
        "\n",
        "baseline_xgb = xgb.XGBClassifier(\n",
        "    objective='multi:softmax',\n",
        "    num_class=len(np.unique(y)),\n",
        "    eval_metric='mlogloss',\n",
        "    use_label_encoder=False,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "baseline_xgb.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "train_preds = baseline_xgb.predict(X_train)\n",
        "val_preds = baseline_xgb.predict(X_val)\n",
        "test_preds = baseline_xgb.predict(X_test)\n",
        "\n",
        "print(\"\\nBaseline XGBoost Results:\")\n",
        "print(\"Training Accuracy:\", accuracy_score(y_train, train_preds))\n",
        "print(\"Validation Accuracy:\", accuracy_score(y_val, val_preds))\n",
        "print(\"Testing Accuracy:\", accuracy_score(y_test, test_preds))\n",
        "\n",
        "# -------------------- XGBoost Hyperparameter Tuning --------------------\n",
        "print(\"\\nStarting XGBoost hyperparameter tuning...\")\n",
        "\n",
        "xgb_params = {\n",
        "    'max_depth': [3, 6],\n",
        "    'learning_rate': [0.1, 0.01],\n",
        "    'n_estimators': [100, 200],\n",
        "    'subsample': [0.8],\n",
        "    'colsample_bytree': [0.8]\n",
        "}\n",
        "\n",
        "xgb_model = xgb.XGBClassifier(\n",
        "    objective='multi:softmax',\n",
        "    num_class=len(np.unique(y)),\n",
        "    eval_metric='mlogloss',\n",
        "    use_label_encoder=False,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "xgb_grid = GridSearchCV(estimator=xgb_model,\n",
        "                        param_grid=xgb_params,\n",
        "                        cv=3,\n",
        "                        n_jobs=-1,\n",
        "                        verbose=1)\n",
        "\n",
        "xgb_grid.fit(X_train, y_train)\n",
        "best_xgb = xgb_grid.best_estimator_\n",
        "\n",
        "# Predictions after tuning\n",
        "xgb_train_preds = best_xgb.predict(X_train)\n",
        "xgb_val_preds = best_xgb.predict(X_val)\n",
        "xgb_test_preds = best_xgb.predict(X_test)\n",
        "\n",
        "print(\"\\nTuned XGBoost Results:\")\n",
        "print(\"Best Parameters:\", xgb_grid.best_params_)\n",
        "print(\"Training Accuracy:\", accuracy_score(y_train, xgb_train_preds))\n",
        "print(\"Validation Accuracy:\", accuracy_score(y_val, xgb_val_preds))\n",
        "print(\"Testing Accuracy:\", accuracy_score(y_test, xgb_test_preds))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pKMgPV0g0gDk",
        "outputId": "8d828667-994f-4482-ea9d-346e18ea27fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training Baseline XGBoost...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [12:55:55] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Baseline XGBoost Results:\n",
            "Training Accuracy: 0.8433712121212121\n",
            "Validation Accuracy: 0.7859090909090909\n",
            "Testing Accuracy: 0.7819393939393939\n",
            "\n",
            "Starting XGBoost hyperparameter tuning...\n",
            "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [13:40:02] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Tuned XGBoost Results:\n",
            "Best Parameters: {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 200, 'subsample': 0.8}\n",
            "Training Accuracy: 0.8343097643097643\n",
            "Validation Accuracy: 0.7917424242424242\n",
            "Testing Accuracy: 0.7901969696969697\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, roc_auc_score\n",
        "import tensorflow as tf # Import tf here for tf.keras.utils.to_categorical\n",
        "\n",
        "# -------------------- Baseline XGBoost Classification Report and AUC-ROC --------------------\n",
        "print(\"\\nClassification Report (Baseline XGBoost - Test Data):\")\n",
        "# Use the baseline_xgb model that was fitted earlier\n",
        "baseline_preds = baseline_xgb.predict(X_test)\n",
        "print(classification_report(y_test, baseline_preds, target_names=[str(cls) for cls in label_encoder.classes_]))\n",
        "\n",
        "try:\n",
        "    # Use the baseline_xgb model for predict_proba as well\n",
        "    baseline_probs = baseline_xgb.predict_proba(X_test)  # shape: (n_samples, n_classes)\n",
        "    # Ensure y_test is one-hot encoded for roc_auc_score if multi_class='ovr'\n",
        "    # Since y_test was kept as integer labels for sklearn models, one-hot encode it here.\n",
        "    y_test_one_hot = tf.keras.utils.to_categorical(y_test, num_classes=len(label_encoder.classes_))\n",
        "    auc_baseline = roc_auc_score(y_test_one_hot, baseline_probs, multi_class='ovr', average='macro')\n",
        "    print(\"AUC-ROC (macro average OvR) Baseline XGBoost:\", auc_baseline)\n",
        "except Exception as e:\n",
        "    print(\"AUC-ROC (Baseline XGBoost) could not be calculated:\", e)\n",
        "\n",
        "\n",
        "# -------------------- Tuned XGBoost Classification Report and AUC-ROC --------------------\n",
        "print(\"\\nClassification Report (Tuned XGBoost - Test Data):\")\n",
        "print(classification_report(y_test, xgb_test_preds, target_names=[str(cls) for cls in label_encoder.classes_]))\n",
        "\n",
        "try:\n",
        "    # Use the best_xgb model for predict_proba\n",
        "    tuned_probs = best_xgb.predict_proba(X_test)\n",
        "    # Ensure y_test is one-hot encoded for roc_auc_score if multi_class='ovr'\n",
        "    y_test_one_hot = tf.keras.utils.to_categorical(y_test, num_classes=len(label_encoder.classes_))\n",
        "    auc_tuned = roc_auc_score(y_test_one_hot, tuned_probs, multi_class='ovr', average='macro')\n",
        "    print(\"AUC-ROC (macro average OvR) Tuned XGBoost:\", auc_tuned)\n",
        "except Exception as e:\n",
        "    print(\"AUC-ROC (Tuned XGBoost) could not be calculated:\", e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MfAH23ZA1Xi8",
        "outputId": "c6b36ec4-414d-408a-eb3d-6cd9b94ffc59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report (Baseline XGBoost - Test Data):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.79      0.78     32629\n",
            "           1       0.79      0.78      0.78     33371\n",
            "\n",
            "    accuracy                           0.78     66000\n",
            "   macro avg       0.78      0.78      0.78     66000\n",
            "weighted avg       0.78      0.78      0.78     66000\n",
            "\n",
            "AUC-ROC (macro average OvR) Baseline XGBoost: 0.8645294887083153\n",
            "\n",
            "Classification Report (Tuned XGBoost - Test Data):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.80      0.79     32629\n",
            "           1       0.80      0.78      0.79     33371\n",
            "\n",
            "    accuracy                           0.79     66000\n",
            "   macro avg       0.79      0.79      0.79     66000\n",
            "weighted avg       0.79      0.79      0.79     66000\n",
            "\n",
            "AUC-ROC (macro average OvR) Tuned XGBoost: 0.8723233383439972\n"
          ]
        }
      ]
    }
  ]
}