{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN/GtV8/rz1Z9ZhbvbL8A+K",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/janaghoniem/Social-Media-Sentiment-Analysis/blob/main/ML_English.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "R9D8ufKNKGZD"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from scipy.sparse import vstack\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "import warnings\n",
        "from sklearn.exceptions import ConvergenceWarning\n",
        "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import ast\n",
        "import re\n",
        "import pickle\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import tensorflow as tf\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')\n",
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Data Science/English preprocessing + pipeline & dataset/English_cleaned.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "collapsed": true,
        "id": "dWXsiNY8KT_L",
        "outputId": "5bfefeb8-8656-434f-98e4-fe42c1a4c944"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                    normalized_tweet  \\\n",
              "0  a that's a bummer. you shoulda got david carr ...   \n",
              "1  is upset that he can't update his facebook by ...   \n",
              "2  i dived many times for the ball. managed to sa...   \n",
              "3     my whole body feels itchy and like its on fire   \n",
              "4  no, it's not behaving at all. i'm mad. why am ...   \n",
              "\n",
              "                                              tokens  \\\n",
              "0  [\"'s\", 'bummer', '.', 'shoulda', 'got', 'david...   \n",
              "1  ['upset', 'ca', \"n't\", 'updat', 'facebook', 't...   \n",
              "2  ['dive', 'mani', 'time', 'ball', '.', 'manag',...   \n",
              "3  ['whole', 'bodi', 'feel', 'itchi', 'like', 'fi...   \n",
              "4  ['no', ',', \"'s\", 'not', 'behav', '.', \"'m\", '...   \n",
              "\n",
              "                                      trigrams_token  target  \n",
              "0  [('a', 'that', \"'s\"), ('that', \"'s\", 'a'), (\"'...      -1  \n",
              "1  [('is', 'upset', 'that'), ('upset', 'that', 'h...      -1  \n",
              "2  [('i', 'dive', 'mani'), ('dive', 'mani', 'time...      -1  \n",
              "3  [('my', 'whole', 'bodi'), ('whole', 'bodi', 'f...      -1  \n",
              "4  [('no', ',', 'it'), (',', 'it', \"'s\"), ('it', ...      -1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ac6c8c03-f4b8-4be1-b7d6-5b8c1728a396\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>normalized_tweet</th>\n",
              "      <th>tokens</th>\n",
              "      <th>trigrams_token</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>a that's a bummer. you shoulda got david carr ...</td>\n",
              "      <td>[\"'s\", 'bummer', '.', 'shoulda', 'got', 'david...</td>\n",
              "      <td>[('a', 'that', \"'s\"), ('that', \"'s\", 'a'), (\"'...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>is upset that he can't update his facebook by ...</td>\n",
              "      <td>['upset', 'ca', \"n't\", 'updat', 'facebook', 't...</td>\n",
              "      <td>[('is', 'upset', 'that'), ('upset', 'that', 'h...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>i dived many times for the ball. managed to sa...</td>\n",
              "      <td>['dive', 'mani', 'time', 'ball', '.', 'manag',...</td>\n",
              "      <td>[('i', 'dive', 'mani'), ('dive', 'mani', 'time...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>my whole body feels itchy and like its on fire</td>\n",
              "      <td>['whole', 'bodi', 'feel', 'itchi', 'like', 'fi...</td>\n",
              "      <td>[('my', 'whole', 'bodi'), ('whole', 'bodi', 'f...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>no, it's not behaving at all. i'm mad. why am ...</td>\n",
              "      <td>['no', ',', \"'s\", 'not', 'behav', '.', \"'m\", '...</td>\n",
              "      <td>[('no', ',', 'it'), (',', 'it', \"'s\"), ('it', ...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ac6c8c03-f4b8-4be1-b7d6-5b8c1728a396')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ac6c8c03-f4b8-4be1-b7d6-5b8c1728a396 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ac6c8c03-f4b8-4be1-b7d6-5b8c1728a396');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-bd9448c4-a63e-49db-851e-588b753be56c\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bd9448c4-a63e-49db-851e-588b753be56c')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-bd9448c4-a63e-49db-851e-588b753be56c button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1) Random Forest"
      ],
      "metadata": {
        "id": "lhgPLtlbAaK0"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EaYgm1BEAaVG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2) SVM"
      ],
      "metadata": {
        "id": "hsZ-6ZDdAajT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Keep the trigram list as is (no joining)\n",
        "X_tokens = df['trigrams_token'].tolist()  # List of lists of trigram strings\n",
        "y = df['target']\n",
        "\n",
        "# Vectorize using CountVectorizer with a custom analyzer that expects pre-tokenized input\n",
        "vectorizer = CountVectorizer(analyzer=lambda x: x)\n",
        "X = vectorizer.fit_transform(X_tokens)\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "# Split into train (60%) and temp (40%)\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "    X, y_encoded, test_size=0.4, stratify=y_encoded, random_state=42\n",
        ")\n",
        "\n",
        "# Split temp into validation (20%) and test (20%)\n",
        "X_val, X_test, y_val, y_test = train_test_split(\n",
        "    X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42\n",
        ")\n",
        "\n",
        "# Train baseline SVM model\n",
        "svm_model = SVC(kernel='linear', probability=False, random_state=42)\n",
        "svm_model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions before tuning\n",
        "y_train_pred = svm_model.predict(X_train)\n",
        "y_val_pred = svm_model.predict(X_val)\n",
        "y_test_pred = svm_model.predict(X_test)\n",
        "\n",
        "print(f\"Baseline SVM Train Accuracy: {accuracy_score(y_train, y_train_pred):.4f}\")\n",
        "print(f\"Baseline SVM Validation Accuracy: {accuracy_score(y_val, y_val_pred):.4f}\")\n",
        "print(f\"Baseline SVM Test Accuracy: {accuracy_score(y_test, y_test_pred):.4f}\")\n",
        "\n",
        "print(\"\\n--- Baseline Classification Report (Test Set) ---\")\n",
        "print(classification_report(y_test, y_test_pred, target_names=label_encoder.classes_.astype(str)))\n",
        "\n",
        "# -------------------- Hyperparameter Tuning --------------------\n",
        "param_grid = {\n",
        "    'C': [0.01, 0.1, 1, 10, 100],  # Regularization parameter\n",
        "    'kernel': ['linear']            # You can try 'rbf' if you want more options\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(\n",
        "    SVC(random_state=42),\n",
        "    param_grid,\n",
        "    cv=3,\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Fit grid search only on training data\n",
        "grid_search.fit(X_train, y_train)\n",
        "best_svm = grid_search.best_estimator_\n",
        "\n",
        "print(\"\\nBest hyperparameters:\", grid_search.best_params_)\n",
        "\n",
        "# Predictions after tuning\n",
        "y_train_pred_tuned = best_svm.predict(X_train)\n",
        "y_val_pred_tuned = best_svm.predict(X_val)\n",
        "y_test_pred_tuned = best_svm.predict(X_test)\n",
        "\n",
        "print(f\"\\nTuned SVM Train Accuracy: {accuracy_score(y_train, y_train_pred_tuned):.4f}\")\n",
        "print(f\"Tuned SVM Validation Accuracy: {accuracy_score(y_val, y_val_pred_tuned):.4f}\")\n",
        "print(f\"Tuned SVM Test Accuracy: {accuracy_score(y_test, y_test_pred_tuned):.4f}\")\n",
        "\n",
        "print(\"\\n--- Tuned Classification Report (Test Set) ---\")\n",
        "print(classification_report(y_test, y_test_pred_tuned, target_names=label_encoder.classes_.astype(str)))\n"
      ],
      "metadata": {
        "id": "Fs07Yxs6a7Q8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3) Logistic regression"
      ],
      "metadata": {
        "id": "Bqx7TUQLAbNw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Keep the trigram list as is\n",
        "X_tokens = df['trigrams_token'].tolist()  # List of lists of trigram strings\n",
        "y = df['target']\n",
        "\n",
        "# Vectorize using CountVectorizer with a custom analyzer that expects pre-tokenized input\n",
        "vectorizer = CountVectorizer(analyzer=lambda x: x)\n",
        "X = vectorizer.fit_transform(X_tokens)\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "# Split into train (60%) and temp (40%)\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "    X, y_encoded, test_size=0.4, stratify=y_encoded, random_state=42\n",
        ")\n",
        "\n",
        "# Split temp into validation (20%) and test (20%)\n",
        "X_val, X_test, y_val, y_test = train_test_split(\n",
        "    X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42\n",
        ")\n",
        "\n",
        "# Train baseline Logistic Regression model\n",
        "logreg_model = LogisticRegression(max_iter=1000, random_state=42)\n",
        "logreg_model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions before tuning\n",
        "y_train_pred = logreg_model.predict(X_train)\n",
        "y_val_pred = logreg_model.predict(X_val)\n",
        "y_test_pred = logreg_model.predict(X_test)\n",
        "\n",
        "print(f\"Baseline Logistic Regression Train Accuracy: {accuracy_score(y_train, y_train_pred):.4f}\")\n",
        "print(f\"Baseline Logistic Regression Validation Accuracy: {accuracy_score(y_val, y_val_pred):.4f}\")\n",
        "print(f\"Baseline Logistic Regression Test Accuracy: {accuracy_score(y_test, y_test_pred):.4f}\")\n",
        "\n",
        "print(\"\\n--- Baseline Classification Report (Test Set) ---\")\n",
        "print(classification_report(y_test, y_test_pred, target_names=label_encoder.classes_.astype(str)))\n",
        "\n",
        "# -------------------- Hyperparameter Tuning --------------------\n",
        "param_grid = {\n",
        "    'C': [0.01, 0.1, 1, 10, 100],      # Inverse of regularization strength\n",
        "    'penalty': ['l2'],                # L2 penalty (default and preferred)\n",
        "    'solver': ['lbfgs'],              # Good solver for multiclass problems\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(\n",
        "    LogisticRegression(max_iter=1000, random_state=42),\n",
        "    param_grid,\n",
        "    cv=3,\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Fit grid search only on training data\n",
        "grid_search.fit(X_train, y_train)\n",
        "best_logreg = grid_search.best_estimator_\n",
        "\n",
        "print(\"\\nBest hyperparameters:\", grid_search.best_params_)\n",
        "\n",
        "# Predictions after tuning\n",
        "y_train_pred_tuned = best_logreg.predict(X_train)\n",
        "y_val_pred_tuned = best_logreg.predict(X_val)\n",
        "y_test_pred_tuned = best_logreg.predict(X_test)\n",
        "\n",
        "print(f\"\\nTuned Logistic Regression Train Accuracy: {accuracy_score(y_train, y_train_pred_tuned):.4f}\")\n",
        "print(f\"Tuned Logistic Regression Validation Accuracy: {accuracy_score(y_val, y_val_pred_tuned):.4f}\")\n",
        "print(f\"Tuned Logistic Regression Test Accuracy: {accuracy_score(y_test, y_test_pred_tuned):.4f}\")\n",
        "\n",
        "print(\"\\n--- Tuned Classification Report (Test Set) ---\")\n",
        "print(classification_report(y_test, y_test_pred_tuned, target_names=label_encoder.classes_.astype(str)))\n"
      ],
      "metadata": {
        "id": "EH9IjOm2AbYn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b82deaa9-22ab-4436-cc69-afdcafc9ed84"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline Logistic Regression Train Accuracy: 0.5984\n",
            "Baseline Logistic Regression Validation Accuracy: 0.5986\n",
            "Baseline Logistic Regression Test Accuracy: 0.5975\n",
            "\n",
            "--- Baseline Classification Report (Test Set) ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.60      0.60      0.60    141567\n",
            "           1       0.59      0.60      0.59    138451\n",
            "\n",
            "    accuracy                           0.60    280018\n",
            "   macro avg       0.60      0.60      0.60    280018\n",
            "weighted avg       0.60      0.60      0.60    280018\n",
            "\n",
            "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
            "\n",
            "Best hyperparameters: {'C': 1, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "\n",
            "Tuned Logistic Regression Train Accuracy: 0.5984\n",
            "Tuned Logistic Regression Validation Accuracy: 0.5986\n",
            "Tuned Logistic Regression Test Accuracy: 0.5975\n",
            "\n",
            "--- Tuned Classification Report (Test Set) ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.60      0.60      0.60    141567\n",
            "           1       0.59      0.60      0.59    138451\n",
            "\n",
            "    accuracy                           0.60    280018\n",
            "   macro avg       0.60      0.60      0.60    280018\n",
            "weighted avg       0.60      0.60      0.60    280018\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4) Naive Bayes"
      ],
      "metadata": {
        "id": "1RNB3zZoAbg8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Keep the trigram list as is\n",
        "X_tokens = df['trigrams_token'].tolist()  # List of lists of trigram strings\n",
        "y = df['target']\n",
        "\n",
        "# Vectorize using CountVectorizer with a custom analyzer that expects pre-tokenized input\n",
        "vectorizer = CountVectorizer(analyzer=lambda x: x)\n",
        "X = vectorizer.fit_transform(X_tokens)\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "# Split into train (60%) and temp (40%)\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "    X, y_encoded, test_size=0.4, stratify=y_encoded, random_state=42\n",
        ")\n",
        "\n",
        "# Split temp into validation (20%) and test (20%)\n",
        "X_val, X_test, y_val, y_test = train_test_split(\n",
        "    X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42\n",
        ")\n",
        "\n",
        "# Train baseline Naive Bayes model\n",
        "nb_model = MultinomialNB()\n",
        "nb_model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions before tuning\n",
        "y_train_pred = nb_model.predict(X_train)\n",
        "y_val_pred = nb_model.predict(X_val)\n",
        "y_test_pred = nb_model.predict(X_test)\n",
        "\n",
        "print(f\"Baseline NB Train Accuracy: {accuracy_score(y_train, y_train_pred):.4f}\")\n",
        "print(f\"Baseline NB Validation Accuracy: {accuracy_score(y_val, y_val_pred):.4f}\")\n",
        "print(f\"Baseline NB Test Accuracy: {accuracy_score(y_test, y_test_pred):.4f}\")\n",
        "\n",
        "print(\"\\n--- Baseline Classification Report (Test Set) ---\")\n",
        "print(classification_report(y_test, y_test_pred, target_names=label_encoder.classes_.astype(str)))\n",
        "\n",
        "# -------------------- Hyperparameter Tuning --------------------\n",
        "param_grid = {\n",
        "    'alpha': [0.001, 0.01, 0.1, 1.0, 10.0]  # Laplace smoothing parameter\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(\n",
        "    MultinomialNB(),\n",
        "    param_grid,\n",
        "    cv=3,\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Fit grid search only on training data\n",
        "grid_search.fit(X_train, y_train)\n",
        "best_nb = grid_search.best_estimator_\n",
        "\n",
        "print(\"\\nBest hyperparameters:\", grid_search.best_params_)\n",
        "\n",
        "# Predictions after tuning\n",
        "y_train_pred_tuned = best_nb.predict(X_train)\n",
        "y_val_pred_tuned = best_nb.predict(X_val)\n",
        "y_test_pred_tuned = best_nb.predict(X_test)\n",
        "\n",
        "print(f\"\\nTuned NB Train Accuracy: {accuracy_score(y_train, y_train_pred_tuned):.4f}\")\n",
        "print(f\"Tuned NB Validation Accuracy: {accuracy_score(y_val, y_val_pred_tuned):.4f}\")\n",
        "print(f\"Tuned NB Test Accuracy: {accuracy_score(y_test, y_test_pred_tuned):.4f}\")\n",
        "\n",
        "print(\"\\n--- Tuned Classification Report (Test Set) ---\")\n",
        "print(classification_report(y_test, y_test_pred_tuned, target_names=label_encoder.classes_.astype(str)))\n"
      ],
      "metadata": {
        "id": "hYodQ4IZAbn_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb3d6b70-8400-4d1d-97d5-fdf6fe058cf5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline NB Train Accuracy: 0.5817\n",
            "Baseline NB Validation Accuracy: 0.5832\n",
            "Baseline NB Test Accuracy: 0.5811\n",
            "\n",
            "--- Baseline Classification Report (Test Set) ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.58      0.60      0.59    141567\n",
            "           1       0.58      0.57      0.57    138451\n",
            "\n",
            "    accuracy                           0.58    280018\n",
            "   macro avg       0.58      0.58      0.58    280018\n",
            "weighted avg       0.58      0.58      0.58    280018\n",
            "\n",
            "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
            "\n",
            "Best hyperparameters: {'alpha': 10.0}\n",
            "\n",
            "Tuned NB Train Accuracy: 0.5817\n",
            "Tuned NB Validation Accuracy: 0.5832\n",
            "Tuned NB Test Accuracy: 0.5811\n",
            "\n",
            "--- Tuned Classification Report (Test Set) ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.58      0.60      0.59    141567\n",
            "           1       0.58      0.57      0.57    138451\n",
            "\n",
            "    accuracy                           0.58    280018\n",
            "   macro avg       0.58      0.58      0.58    280018\n",
            "weighted avg       0.58      0.58      0.58    280018\n",
            "\n"
          ]
        }
      ]
    }
  ]
}