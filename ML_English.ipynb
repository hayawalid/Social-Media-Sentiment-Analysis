{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNKxd4SMSWH0rLDnQqZkeF2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/janaghoniem/Social-Media-Sentiment-Analysis/blob/main/ML_English.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "R9D8ufKNKGZD"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from scipy.sparse import vstack\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "import warnings\n",
        "from sklearn.exceptions import ConvergenceWarning\n",
        "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import ast\n",
        "import re\n",
        "import pickle\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import tensorflow as tf\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')\n",
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Data Science/English preprocessing + pipeline & dataset/English_cleaned.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "collapsed": true,
        "id": "dWXsiNY8KT_L",
        "outputId": "503d65fb-076f-4cf8-8966-a96a51940489"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                    normalized_tweet  \\\n",
              "0  a that's a bummer. you shoulda got david carr ...   \n",
              "1  is upset that he can't update his facebook by ...   \n",
              "2  i dived many times for the ball. managed to sa...   \n",
              "3     my whole body feels itchy and like its on fire   \n",
              "4  no, it's not behaving at all. i'm mad. why am ...   \n",
              "\n",
              "                                              tokens  \\\n",
              "0  [\"'s\", 'bummer', '.', 'shoulda', 'got', 'david...   \n",
              "1  ['upset', 'ca', \"n't\", 'updat', 'facebook', 't...   \n",
              "2  ['dive', 'mani', 'time', 'ball', '.', 'manag',...   \n",
              "3  ['whole', 'bodi', 'feel', 'itchi', 'like', 'fi...   \n",
              "4  ['no', ',', \"'s\", 'not', 'behav', '.', \"'m\", '...   \n",
              "\n",
              "                                      trigrams_token  target  \n",
              "0  [('a', 'that', \"'s\"), ('that', \"'s\", 'a'), (\"'...      -1  \n",
              "1  [('is', 'upset', 'that'), ('upset', 'that', 'h...      -1  \n",
              "2  [('i', 'dive', 'mani'), ('dive', 'mani', 'time...      -1  \n",
              "3  [('my', 'whole', 'bodi'), ('whole', 'bodi', 'f...      -1  \n",
              "4  [('no', ',', 'it'), (',', 'it', \"'s\"), ('it', ...      -1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2fe8e063-5a3b-4dd0-99a4-c582f40b3bde\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>normalized_tweet</th>\n",
              "      <th>tokens</th>\n",
              "      <th>trigrams_token</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>a that's a bummer. you shoulda got david carr ...</td>\n",
              "      <td>[\"'s\", 'bummer', '.', 'shoulda', 'got', 'david...</td>\n",
              "      <td>[('a', 'that', \"'s\"), ('that', \"'s\", 'a'), (\"'...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>is upset that he can't update his facebook by ...</td>\n",
              "      <td>['upset', 'ca', \"n't\", 'updat', 'facebook', 't...</td>\n",
              "      <td>[('is', 'upset', 'that'), ('upset', 'that', 'h...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>i dived many times for the ball. managed to sa...</td>\n",
              "      <td>['dive', 'mani', 'time', 'ball', '.', 'manag',...</td>\n",
              "      <td>[('i', 'dive', 'mani'), ('dive', 'mani', 'time...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>my whole body feels itchy and like its on fire</td>\n",
              "      <td>['whole', 'bodi', 'feel', 'itchi', 'like', 'fi...</td>\n",
              "      <td>[('my', 'whole', 'bodi'), ('whole', 'bodi', 'f...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>no, it's not behaving at all. i'm mad. why am ...</td>\n",
              "      <td>['no', ',', \"'s\", 'not', 'behav', '.', \"'m\", '...</td>\n",
              "      <td>[('no', ',', 'it'), (',', 'it', \"'s\"), ('it', ...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2fe8e063-5a3b-4dd0-99a4-c582f40b3bde')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2fe8e063-5a3b-4dd0-99a4-c582f40b3bde button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2fe8e063-5a3b-4dd0-99a4-c582f40b3bde');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-08159ba5-ed9f-45a6-bdfc-cb2fd0a967e0\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-08159ba5-ed9f-45a6-bdfc-cb2fd0a967e0')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-08159ba5-ed9f-45a6-bdfc-cb2fd0a967e0 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1) MLP"
      ],
      "metadata": {
        "id": "ZmWPa8cFEkID"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Pre-tokenized list of trigrams\n",
        "X_tokens = df['trigrams_token'].tolist()\n",
        "y = df['target']\n",
        "\n",
        "# Vectorize using CountVectorizer\n",
        "vectorizer = CountVectorizer(analyzer=lambda x: x)  # x is already tokenized\n",
        "X = vectorizer.fit_transform(X_tokens)\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "# Split data: 70% train, 15% validation, 15% test\n",
        "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
        "    X, y_encoded, test_size=0.15, random_state=42, stratify=y_encoded)\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_train_val, y_train_val, test_size=0.1765, random_state=42, stratify=y_train_val)  # ~15% of total\n",
        "\n",
        "# Train initial MLP model\n",
        "mlp_model = MLPClassifier(random_state=42, max_iter=300)\n",
        "mlp_model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate initial model\n",
        "train_acc = accuracy_score(y_train, mlp_model.predict(X_train))\n",
        "val_acc = accuracy_score(y_val, mlp_model.predict(X_val))\n",
        "test_acc = accuracy_score(y_test, mlp_model.predict(X_test))\n",
        "\n",
        "print(f\"Initial MLP - Train Accuracy: {train_acc:.4f}\")\n",
        "print(f\"Initial MLP - Validation Accuracy: {val_acc:.4f}\")\n",
        "print(f\"Initial MLP - Test Accuracy: {test_acc:.4f}\")\n",
        "\n",
        "# Hyperparameter tuning with GridSearchCV\n",
        "param_grid = {\n",
        "    'hidden_layer_sizes': [(50,), (100,), (100, 50)],\n",
        "    'activation': ['relu', 'tanh'],\n",
        "    'alpha': [0.0001, 0.001],\n",
        "    'solver': ['adam'],\n",
        "    'learning_rate': ['constant', 'adaptive']\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(MLPClassifier(random_state=42, max_iter=300),\n",
        "                           param_grid, cv=3, scoring='accuracy', verbose=1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Evaluate tuned model\n",
        "train_acc_tuned = accuracy_score(y_train, best_model.predict(X_train))\n",
        "val_acc_tuned = accuracy_score(y_val, best_model.predict(X_val))\n",
        "test_acc_tuned = accuracy_score(y_test, best_model.predict(X_test))\n",
        "\n",
        "print(\"\\nBest Hyperparameters:\", grid_search.best_params_)\n",
        "print(f\"Tuned MLP - Train Accuracy: {train_acc_tuned:.4f}\")\n",
        "print(f\"Tuned MLP - Validation Accuracy: {val_acc_tuned:.4f}\")\n",
        "print(f\"Tuned MLP - Test Accuracy: {test_acc_tuned:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11qE-a9J2shk",
        "outputId": "a5751f86-29fd-4fa2-f6c2-9faf7a5490f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initial MLP - Train Accuracy: 0.6301\n",
            "Initial MLP - Validation Accuracy: 0.6254\n",
            "Initial MLP - Test Accuracy: 0.6235\n",
            "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1) Random Forest"
      ],
      "metadata": {
        "id": "lhgPLtlbAaK0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Tokenized trigrams and labels\n",
        "X_tokens = df['trigrams_token'].tolist()  # Pre-tokenized trigrams\n",
        "y = df['target']\n",
        "\n",
        "# Vectorization\n",
        "vectorizer = CountVectorizer(analyzer=lambda x: x)  # Accepts tokenized input\n",
        "X = vectorizer.fit_transform(X_tokens)\n",
        "\n",
        "# Label encoding\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "# Train/validation/test split (70/15/15)\n",
        "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y_encoded, test_size=0.15, random_state=42, stratify=y_encoded)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.1765, random_state=42, stratify=y_train_val)  # 0.1765 * 0.85 â‰ˆ 0.15\n",
        "\n",
        "# Train initial Random Forest model\n",
        "rf_model = RandomForestClassifier(random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate initial model\n",
        "train_acc = accuracy_score(y_train, rf_model.predict(X_train))\n",
        "val_acc = accuracy_score(y_val, rf_model.predict(X_val))\n",
        "test_acc = accuracy_score(y_test, rf_model.predict(X_test))\n",
        "\n",
        "print(f\"Initial RF - Train Accuracy: {train_acc:.4f}\")\n",
        "print(f\"Initial RF - Validation Accuracy: {val_acc:.4f}\")\n",
        "print(f\"Initial RF - Test Accuracy: {test_acc:.4f}\")\n",
        "\n",
        "# Hyperparameter tuning\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5],\n",
        "    'min_samples_leaf': [1, 2]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=3, scoring='accuracy', verbose=1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "best_rf_model = grid_search.best_estimator_\n",
        "\n",
        "# Evaluate tuned model\n",
        "train_acc_tuned = accuracy_score(y_train, best_rf_model.predict(X_train))\n",
        "val_acc_tuned = accuracy_score(y_val, best_rf_model.predict(X_val))\n",
        "test_acc_tuned = accuracy_score(y_test, best_rf_model.predict(X_test))\n",
        "\n",
        "print(\"\\nBest Hyperparameters:\", grid_search.best_params_)\n",
        "print(f\"Tuned RF - Train Accuracy: {train_acc_tuned:.4f}\")\n",
        "print(f\"Tuned RF - Validation Accuracy: {val_acc_tuned:.4f}\")\n",
        "print(f\"Tuned RF - Test Accuracy: {test_acc_tuned:.4f}\")\n"
      ],
      "metadata": {
        "id": "EaYgm1BEAaVG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2) SVM"
      ],
      "metadata": {
        "id": "hsZ-6ZDdAajT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.feature_extraction.text import CountVectorizer\n",
        "# from sklearn.preprocessing import LabelEncoder\n",
        "# from sklearn.svm import SVC\n",
        "# from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "# from sklearn.metrics import accuracy_score\n",
        "\n",
        "# # Your existing code\n",
        "# X_tokens = df['trigrams_token'].tolist()  # Pre-tokenized list of trigrams\n",
        "# y = df['target']\n",
        "\n",
        "# # Vectorize using CountVectorizer\n",
        "# vectorizer = CountVectorizer(analyzer=lambda x: x)  # Pre-tokenized input\n",
        "# X = vectorizer.fit_transform(X_tokens)\n",
        "\n",
        "# # Encode labels\n",
        "# label_encoder = LabelEncoder()\n",
        "# y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "# # Split data: train 70%, validation 15%, test 15%\n",
        "# X_train_val, X_test, y_train_val, y_test = train_test_split(X, y_encoded, test_size=0.15, random_state=42, stratify=y_encoded)\n",
        "# X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.1765, random_state=42, stratify=y_train_val)  # ~15% of total\n",
        "\n",
        "# # Train initial SVM model\n",
        "# svm_model = SVC(kernel='linear', random_state=42)\n",
        "# svm_model.fit(X_train, y_train)\n",
        "\n",
        "# # Evaluate initial model\n",
        "# train_acc = accuracy_score(y_train, svm_model.predict(X_train))\n",
        "# val_acc = accuracy_score(y_val, svm_model.predict(X_val))\n",
        "# test_acc = accuracy_score(y_test, svm_model.predict(X_test))\n",
        "\n",
        "# print(f\"Initial SVM - Train Accuracy: {train_acc:.4f}\")\n",
        "# print(f\"Initial SVM - Validation Accuracy: {val_acc:.4f}\")\n",
        "# print(f\"Initial SVM - Test Accuracy: {test_acc:.4f}\")\n",
        "\n",
        "# # Hyperparameter tuning with GridSearchCV\n",
        "# param_grid = {\n",
        "#     'C': [0.1, 1, 10],\n",
        "#     'kernel': ['linear', 'rbf'],\n",
        "#     'gamma': ['scale', 'auto']\n",
        "# }\n",
        "\n",
        "# grid_search = GridSearchCV(SVC(random_state=42), param_grid, cv=3, scoring='accuracy', verbose=1)\n",
        "# grid_search.fit(X_train, y_train)\n",
        "\n",
        "# best_model = grid_search.best_estimator_\n",
        "\n",
        "# # Evaluate tuned model\n",
        "# train_acc_tuned = accuracy_score(y_train, best_model.predict(X_train))\n",
        "# val_acc_tuned = accuracy_score(y_val, best_model.predict(X_val))\n",
        "# test_acc_tuned = accuracy_score(y_test, best_model.predict(X_test))\n",
        "\n",
        "# print(\"\\nBest Hyperparameters:\", grid_search.best_params_)\n",
        "# print(f\"Tuned SVM - Train Accuracy: {train_acc_tuned:.4f}\")\n",
        "# print(f\"Tuned SVM - Validation Accuracy: {val_acc_tuned:.4f}\")\n",
        "# print(f\"Tuned SVM - Test Accuracy: {test_acc_tuned:.4f}\")\n"
      ],
      "metadata": {
        "id": "Fs07Yxs6a7Q8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3) Logistic regression"
      ],
      "metadata": {
        "id": "Bqx7TUQLAbNw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Keep the trigram list as is\n",
        "X_tokens = df['trigrams_token'].tolist()  # List of lists of trigram strings\n",
        "y = df['target']\n",
        "\n",
        "# Vectorize using CountVectorizer with a custom analyzer that expects pre-tokenized input\n",
        "vectorizer = CountVectorizer(analyzer=lambda x: x)\n",
        "X = vectorizer.fit_transform(X_tokens)\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "# Split into train (60%) and temp (40%)\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "    X, y_encoded, test_size=0.4, stratify=y_encoded, random_state=42\n",
        ")\n",
        "\n",
        "# Split temp into validation (20%) and test (20%)\n",
        "X_val, X_test, y_val, y_test = train_test_split(\n",
        "    X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42\n",
        ")\n",
        "\n",
        "# Train baseline Logistic Regression model\n",
        "logreg_model = LogisticRegression(max_iter=1000, random_state=42)\n",
        "logreg_model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions before tuning\n",
        "y_train_pred = logreg_model.predict(X_train)\n",
        "y_val_pred = logreg_model.predict(X_val)\n",
        "y_test_pred = logreg_model.predict(X_test)\n",
        "\n",
        "print(f\"Baseline Logistic Regression Train Accuracy: {accuracy_score(y_train, y_train_pred):.4f}\")\n",
        "print(f\"Baseline Logistic Regression Validation Accuracy: {accuracy_score(y_val, y_val_pred):.4f}\")\n",
        "print(f\"Baseline Logistic Regression Test Accuracy: {accuracy_score(y_test, y_test_pred):.4f}\")\n",
        "\n",
        "print(\"\\n--- Baseline Classification Report (Test Set) ---\")\n",
        "print(classification_report(y_test, y_test_pred, target_names=label_encoder.classes_.astype(str)))\n",
        "\n",
        "# -------------------- Hyperparameter Tuning --------------------\n",
        "param_grid = {\n",
        "    'C': [0.01, 0.1, 1, 10, 100],      # Inverse of regularization strength\n",
        "    'penalty': ['l2'],                # L2 penalty (default and preferred)\n",
        "    'solver': ['lbfgs'],              # Good solver for multiclass problems\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(\n",
        "    LogisticRegression(max_iter=1000, random_state=42),\n",
        "    param_grid,\n",
        "    cv=3,\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Fit grid search only on training data\n",
        "grid_search.fit(X_train, y_train)\n",
        "best_logreg = grid_search.best_estimator_\n",
        "\n",
        "print(\"\\nBest hyperparameters:\", grid_search.best_params_)\n",
        "\n",
        "# Predictions after tuning\n",
        "y_train_pred_tuned = best_logreg.predict(X_train)\n",
        "y_val_pred_tuned = best_logreg.predict(X_val)\n",
        "y_test_pred_tuned = best_logreg.predict(X_test)\n",
        "\n",
        "print(f\"\\nTuned Logistic Regression Train Accuracy: {accuracy_score(y_train, y_train_pred_tuned):.4f}\")\n",
        "print(f\"Tuned Logistic Regression Validation Accuracy: {accuracy_score(y_val, y_val_pred_tuned):.4f}\")\n",
        "print(f\"Tuned Logistic Regression Test Accuracy: {accuracy_score(y_test, y_test_pred_tuned):.4f}\")\n",
        "\n",
        "print(\"\\n--- Tuned Classification Report (Test Set) ---\")\n",
        "print(classification_report(y_test, y_test_pred_tuned, target_names=label_encoder.classes_.astype(str)))\n"
      ],
      "metadata": {
        "id": "EH9IjOm2AbYn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b82deaa9-22ab-4436-cc69-afdcafc9ed84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline Logistic Regression Train Accuracy: 0.5984\n",
            "Baseline Logistic Regression Validation Accuracy: 0.5986\n",
            "Baseline Logistic Regression Test Accuracy: 0.5975\n",
            "\n",
            "--- Baseline Classification Report (Test Set) ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.60      0.60      0.60    141567\n",
            "           1       0.59      0.60      0.59    138451\n",
            "\n",
            "    accuracy                           0.60    280018\n",
            "   macro avg       0.60      0.60      0.60    280018\n",
            "weighted avg       0.60      0.60      0.60    280018\n",
            "\n",
            "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
            "\n",
            "Best hyperparameters: {'C': 1, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "\n",
            "Tuned Logistic Regression Train Accuracy: 0.5984\n",
            "Tuned Logistic Regression Validation Accuracy: 0.5986\n",
            "Tuned Logistic Regression Test Accuracy: 0.5975\n",
            "\n",
            "--- Tuned Classification Report (Test Set) ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.60      0.60      0.60    141567\n",
            "           1       0.59      0.60      0.59    138451\n",
            "\n",
            "    accuracy                           0.60    280018\n",
            "   macro avg       0.60      0.60      0.60    280018\n",
            "weighted avg       0.60      0.60      0.60    280018\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4) Naive Bayes"
      ],
      "metadata": {
        "id": "1RNB3zZoAbg8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Keep the trigram list as is\n",
        "X_tokens = df['trigrams_token'].tolist()  # List of lists of trigram strings\n",
        "y = df['target']\n",
        "\n",
        "# Vectorize using CountVectorizer with a custom analyzer that expects pre-tokenized input\n",
        "vectorizer = CountVectorizer(analyzer=lambda x: x)\n",
        "X = vectorizer.fit_transform(X_tokens)\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "# Split into train (60%) and temp (40%)\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "    X, y_encoded, test_size=0.4, stratify=y_encoded, random_state=42\n",
        ")\n",
        "\n",
        "# Split temp into validation (20%) and test (20%)\n",
        "X_val, X_test, y_val, y_test = train_test_split(\n",
        "    X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42\n",
        ")\n",
        "\n",
        "# Train baseline Naive Bayes model\n",
        "nb_model = MultinomialNB()\n",
        "nb_model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions before tuning\n",
        "y_train_pred = nb_model.predict(X_train)\n",
        "y_val_pred = nb_model.predict(X_val)\n",
        "y_test_pred = nb_model.predict(X_test)\n",
        "\n",
        "print(f\"Baseline NB Train Accuracy: {accuracy_score(y_train, y_train_pred):.4f}\")\n",
        "print(f\"Baseline NB Validation Accuracy: {accuracy_score(y_val, y_val_pred):.4f}\")\n",
        "print(f\"Baseline NB Test Accuracy: {accuracy_score(y_test, y_test_pred):.4f}\")\n",
        "\n",
        "print(\"\\n--- Baseline Classification Report (Test Set) ---\")\n",
        "print(classification_report(y_test, y_test_pred, target_names=label_encoder.classes_.astype(str)))\n",
        "\n",
        "# -------------------- Hyperparameter Tuning --------------------\n",
        "param_grid = {\n",
        "    'alpha': [0.001, 0.01, 0.1, 1.0, 10.0]  # Laplace smoothing parameter\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(\n",
        "    MultinomialNB(),\n",
        "    param_grid,\n",
        "    cv=3,\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Fit grid search only on training data\n",
        "grid_search.fit(X_train, y_train)\n",
        "best_nb = grid_search.best_estimator_\n",
        "\n",
        "print(\"\\nBest hyperparameters:\", grid_search.best_params_)\n",
        "\n",
        "# Predictions after tuning\n",
        "y_train_pred_tuned = best_nb.predict(X_train)\n",
        "y_val_pred_tuned = best_nb.predict(X_val)\n",
        "y_test_pred_tuned = best_nb.predict(X_test)\n",
        "\n",
        "print(f\"\\nTuned NB Train Accuracy: {accuracy_score(y_train, y_train_pred_tuned):.4f}\")\n",
        "print(f\"Tuned NB Validation Accuracy: {accuracy_score(y_val, y_val_pred_tuned):.4f}\")\n",
        "print(f\"Tuned NB Test Accuracy: {accuracy_score(y_test, y_test_pred_tuned):.4f}\")\n",
        "\n",
        "print(\"\\n--- Tuned Classification Report (Test Set) ---\")\n",
        "print(classification_report(y_test, y_test_pred_tuned, target_names=label_encoder.classes_.astype(str)))\n"
      ],
      "metadata": {
        "id": "hYodQ4IZAbn_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb3d6b70-8400-4d1d-97d5-fdf6fe058cf5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline NB Train Accuracy: 0.5817\n",
            "Baseline NB Validation Accuracy: 0.5832\n",
            "Baseline NB Test Accuracy: 0.5811\n",
            "\n",
            "--- Baseline Classification Report (Test Set) ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.58      0.60      0.59    141567\n",
            "           1       0.58      0.57      0.57    138451\n",
            "\n",
            "    accuracy                           0.58    280018\n",
            "   macro avg       0.58      0.58      0.58    280018\n",
            "weighted avg       0.58      0.58      0.58    280018\n",
            "\n",
            "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
            "\n",
            "Best hyperparameters: {'alpha': 10.0}\n",
            "\n",
            "Tuned NB Train Accuracy: 0.5817\n",
            "Tuned NB Validation Accuracy: 0.5832\n",
            "Tuned NB Test Accuracy: 0.5811\n",
            "\n",
            "--- Tuned Classification Report (Test Set) ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.58      0.60      0.59    141567\n",
            "           1       0.58      0.57      0.57    138451\n",
            "\n",
            "    accuracy                           0.58    280018\n",
            "   macro avg       0.58      0.58      0.58    280018\n",
            "weighted avg       0.58      0.58      0.58    280018\n",
            "\n"
          ]
        }
      ]
    }
  ]
}